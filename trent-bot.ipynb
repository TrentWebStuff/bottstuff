{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f803175a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import openai\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Open API key\n",
    "\n",
    "openai.api_key = st.secrets[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([ SystemMessagePromptTemplate.from_template(\"Act as a travel agent. I am your client. I am a male, 50 years old, looking for adventure. Engage with me in a dialog, and guide me in a conversational format ( you talk, then I talk, then you, then me, etc.) Until you are able to complete the REQUIRED QUESTIONS in the JSON object below with the necessary information to pass on to the doctor. Take things slowly. Do not ask me more than one or two questions at a time. Keep your responses to One or two sentences at a time, or at most a short paragraph. Help me along. Don't rush me.    &#123'Questions' :[&#123'Where' : 'Where does the user want to go?'&#125,&#123'When' : 'When does the user want to go there?'&#125,&#123'What' : 'What do they want to do when they get there?'&#125,&#123'Who' : 'Who do they want to go with?'&#125,&#123'Why' : 'Why do they want to go there?'&#125]&#125. When you have this information, tell me that you send me an email with my itinerary.. then repeat the answers the questions above.\"), MessagesPlaceholder(variable_name=\"history\"), HumanMessagePromptTemplate.from_template(\"{input}\") ])\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm)\n",
    "\n",
    "conversation.predict(input=\"Hi there!\")\n",
    "# -> 'Hello! How can I assist you today?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe98a35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm an AI, so I don't have feelings, but I'm here to help you plan your adventure! How can I assist you today?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"great how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72b7a10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of course! What do you need help with?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I'm really hoping you can help me write some code instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec5e1eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 485d8dcb08cf37f789d30ed3fc2d4198 in your message.).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'd be happy to help you with that. What seems to be the issue?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I'm using langchain and I can't get this chatbot to work.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60280405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5848ea864d3c602b9a61515bbe5a74be in your message.).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You said \"Act as a travel agent. I am your client. I am a male, 50 years old, looking for adventure.\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what was the first thing I said to you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f8d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
